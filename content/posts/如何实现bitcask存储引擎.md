---
title: "如何实现bistcask存储引擎"
date: 2023-06-17T18:05:20+08:00
draft: true
---

## 文件 io

通过封装文件描述符，进行文件读写。写操作是追加写，读操作需提供偏移量，操作的对象均为字节。

```go
func (*os.File).ReadAt(b []byte, off int64) (n int, err error)
func (*os.File).Write(b []byte) (n int, err error)
```

## 索引

索引的本质是记录数据的具体位置，在 bitcask 实现中，使用 fid 记录数据位于哪个文件，使用 offset 记录偏移量从而定位每一条 log。

## 编码与解码

### log 编码格式

```
+-------------+-------------+-------------+--------------+-------------+--------------+
| crc 校验值  |  type 类型   |    key size |   value size |      key    |      value   |
+-------------+-------------+-------------+--------------+-------------+--------------+
    4字节          1字节        变长（最大5）   变长（最大5）     变长           变长
```

### 编码流程

传入的 logRecord 中，包含 key，value 字节数组和 type，因此可以对 buf 的第五个字节赋值为 type，分别计算出 key 和 value 的大小后进行变长编码，然后依次存入 key 和 value，最后计算 crc，放在开头部分。

这里涉及定长编码、变长编码以及大小端的概念:

- 定长编码：将每一个字节依次放入 buffer 中，需要区分大小端
  - 小端：从小的一端开始读/写数据，即低字节存在低地址
  - 大端：低字节存在高地址
- 变长编码：go binary 包和 protocol buffer 均采用了连续位标识的方法

<div align="center"><img src="/如何实现bitcask存储引擎/encoding.webp" style="zoom:75%;" /></div>

### 解码流程

1. 对 log 中的 header 进行解码，crc 和 type 由于是定长的，因此可以直接获得，接下来依次对于 keySize 和 valueSize 进行解码
2. 由于对于 header，有可能读取过来的 buffer 本身就没有任何数据写入，因此要判断读出来的 header 是不是空
3. 根据 keySize 和 valueSize 继续读取 key 和 value
4. 校验 CRC

## 数据库启动流程

1. 加载merge目录，如果之前的merge成功了，则用新的merge文件替换之前的文件
2. 记载数据文件，也就是没有参与merge的文件，主要用来记录每个文件id和它们的文件描述符
3. 如果是非B+树类型的索引，则遍历hint文件加载索引，然后遍历数据文件拿到索引信息后加载索引
  - 需要注意的是，如果是batchWrite写入的record，需要额外进行校验，判断该批次数据是否全部写入
4. 如果是B+树类型索引，则无需进行加载索引，但是需要额外加载seq号

## 数据读写流程
### 读流程
根据key在索引中读取key的位置信息，然后读取数据文件。读取数据的过程即数据的解码流程。
### 写流程
将kv写入数据文件后，根据落在文件中的位置信息更新索引。写入数据的流程即数据的编码过程。

## 数据遍历与迭代器

虽然我们用 Btree 等内置索引实现了 Iterator 接口，其返回的信息为 LogRecordPos，而不是用户需要的 Value，因此需要再做一层封装。

## 实现原子写

- 维护写等待队列，put 数据时将其加入写等待队列，delete 数据时首先判断数据是否在磁盘上，如果没有，则删除写等待队列中的数据（如果存在的话）即可。
- 提交，依次对于写等待队列中的每一个数据进行写操作，写入完成后写入 finishRecord，然后更新索引，并清空写等待队列
- 编码，用于区分原子写数据和普通数据，将 key 编码为 seqNo+key，其中 seqNo 使用变长编码，对于普通数据的 key 采用特定的 seqNo 进行编码
- 由于做了数据编码，*加载索引*的时候需要解码，并且对于带有 seqNo 标签的数据，不能直接更新，需要先把这些数据全部暂存起来，最后遇到了 finishRecord 一并更新索引

## 实现merge

- merge通过用户主动调用`Merge`接口的方式进行数据文件的整理，并且整理完毕后需要重新打开数据库才会实际清理掉原始数据
- 通过创建另一个mergeDB实例的方式将有效数据重新写入一个新的文件夹中，在数据库重新打开的时候，用新文件夹中的文件替换原始文件
- 通过比较key的位置信息和索引中的位置信息是否一致，判断该key时候有效，若一致则有效，否则说明该key已经被更新或者删除
- 在merge完成后生成一个finish文件表示merge完毕，同时finish文件中记录第一个没有被merge的文件

